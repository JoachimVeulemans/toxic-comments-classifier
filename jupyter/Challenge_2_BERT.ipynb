{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/1a/364556102943cacde1ee00fdcae3b1615b39e52649eddbf54953e5b144c9/transformers-2.2.1-py3-none-any.whl (364kB)\n",
      "\u001b[K     |████████████████████████████████| 368kB 10.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex (from transformers)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/db/4b29a0adec5881542cd81cb5d1929b5c0787003c5740b3c921e627d9c2e5/regex-2019.12.9.tar.gz (669kB)\n",
      "\u001b[K     |████████████████████████████████| 675kB 15.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from transformers) (2.22.0)\n",
      "Collecting sacremoses (from transformers)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
      "\u001b[K     |████████████████████████████████| 860kB 20.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from transformers) (4.39.0)\n",
      "Requirement already satisfied: numpy in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from transformers) (1.16.2)\n",
      "Requirement already satisfied: boto3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from transformers) (1.10.28)\n",
      "Collecting sentencepiece (from transformers)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 22.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: six in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from sacremoses->transformers) (1.13.0)\n",
      "Requirement already satisfied: click in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.0)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.28 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from boto3->transformers) (1.13.28)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.28->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.28->boto3->transformers) (2.8.0)\n",
      "Building wheels for collected packages: regex, sacremoses\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for regex: filename=regex-2019.12.9-cp36-cp36m-linux_x86_64.whl size=608292 sha256=b447971564656c6a3f9eaeead0c7a50d697e9644e032cceba853185345fb7564\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/0d/fb/b3/a89169557229468c49ca64f6839418f22461f6ee0a74f342b1\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=e996fb68496aed0d7bffdb9a3eb9a5be06b4f403f8d75f41e248a8d61fa6d058\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
      "Successfully built regex sacremoses\n",
      "Installing collected packages: regex, sacremoses, sentencepiece, transformers\n",
      "Successfully installed regex-2019.12.9 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/bb20f9b9e24f9a6250f95a432f8d9a7d745f8d24039d7a5a6eaadb7783ba/kaggle-1.5.6.tar.gz (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 10.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (1.24.2)\n",
      "Requirement already satisfied: six>=1.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (1.13.0)\n",
      "Requirement already satisfied: certifi in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (2019.9.11)\n",
      "Requirement already satisfied: python-dateutil in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (2.8.0)\n",
      "Requirement already satisfied: requests in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from kaggle) (4.39.0)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading https://files.pythonhosted.org/packages/92/5f/7b84a0bba8a0fdd50c046f8b57dcf179dc16237ad33446079b7c484de04c/python-slugify-4.0.0.tar.gz\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->kaggle) (3.0.4)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/a5/c0b6468d3824fe3fde30dbb5e1f687b291608f9473681bbf7dabbf5a87d7/text_unidecode-1.3-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 23.5MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.6-cp36-none-any.whl size=72859 sha256=16d7e2fb0608f32b23ea61d8eab91c5d5ed2839fe9cf9f6e9d81afcafd7a4a35\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/57/4e/e8/bb28d035162fb8f17f8ca5d42c3230e284c6aa565b42b72674\n",
      "  Building wheel for python-slugify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-slugify: filename=python_slugify-4.0.0-py2.py3-none-any.whl size=5487 sha256=9ef18ae270c8063cf606bf50d90d10c538ab27b749a76c5c27b2446b1d9e5bbb\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/11/94/81/312969455540cb0e6a773e5d68a73c14128bfdfd4a7969bb4f\n",
      "Successfully built kaggle python-slugify\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.6 python-slugify-4.0.0 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/58/d78c39b2fcbe3358a54a4042219eaf78bc196e771dc02a6f540ee2194a2e/fastai-1.0.59.tar.gz (3.5MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5MB 24.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: bottleneck in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (1.2.1)\n",
      "Collecting fastprogress>=0.1.19 (from fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/4f/eb76f71e7da768325e029b10a443aa015236a04217ec482e861fae7ccb8f/fastprogress-0.1.22-py3-none-any.whl\n",
      "Requirement already satisfied: beautifulsoup4 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (4.8.0)\n",
      "Requirement already satisfied: matplotlib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (3.1.2)\n",
      "Requirement already satisfied: numexpr in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (1.16.2)\n",
      "Collecting nvidia-ml-py3 (from fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/64/cce82bddb80c0b0f5c703bbdafa94bfb69a1c5ad7a79cff00b482468f0d3/nvidia-ml-py3-7.352.0.tar.gz\n",
      "Requirement already satisfied: pandas in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (0.23.4)\n",
      "Requirement already satisfied: packaging in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (19.2)\n",
      "Requirement already satisfied: Pillow in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (6.2.0)\n",
      "Requirement already satisfied: pyyaml in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (5.1.2)\n",
      "Requirement already satisfied: requests in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (2.22.0)\n",
      "Requirement already satisfied: scipy in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (1.1.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (1.3.1)\n",
      "Collecting spacy>=2.0.18 (from fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4MB 34.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from fastai) (0.2.1)\n",
      "Collecting dataclasses (from fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n",
      "Requirement already satisfied: soupsieve>=1.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from beautifulsoup4->fastai) (1.9.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from matplotlib->fastai) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pandas->fastai) (2019.3)\n",
      "Requirement already satisfied: six in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from packaging->fastai) (1.13.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests->fastai) (1.24.2)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy>=2.0.18->fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy>=2.0.18->fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/b5/3e1714ebda8fd7c5859f9b216e381adc0a38b962f071568fd00d67e1b1ca/cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting plac<1.2.0,>=0.9.6 (from spacy>=2.0.18->fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from spacy>=2.0.18->fastai) (41.4.0)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy>=2.0.18->fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 41.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7 (from spacy>=2.0.18->fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/d5/46ff975f0d7d055cf95557b944fd5d29d9dfb37a4341038e070f212b24fe/catalogue-0.0.8-py2.py3-none-any.whl\n",
      "Collecting thinc<7.4.0,>=7.3.0 (from spacy>=2.0.18->fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 32.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.5.0,>=0.4.0 (from spacy>=2.0.18->fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 42.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.4.0 (from spacy>=2.0.18->fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/ef/e8266e158ed32bf5f723fac862b6518833d0b53ca183165a8718f212c0d5/wasabi-0.4.2-py3-none-any.whl\n",
      "Collecting srsly<1.1.0,>=0.1.0 (from spacy>=2.0.18->fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/fb/34136c7b2ad04d4472dd9ea86536f5e9fb71fb0eb78edc8dad76a3f9edf2/srsly-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (185kB)\n",
      "\u001b[K     |████████████████████████████████| 194kB 62.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai) (0.23)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.0.18->fastai) (4.39.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai) (7.2.0)\n",
      "Building wheels for collected packages: fastai, nvidia-ml-py3\n",
      "  Building wheel for fastai (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fastai: filename=fastai-1.0.59-cp36-none-any.whl size=235956 sha256=42a9c321dd81c014b7fcb5124718f6ac5d901b21840a26c5d7bd9bf96040734b\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/45/3e/33/2286dfb90e4d3e197356552c0743678bb158d47f6e05540029\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-cp36-none-any.whl size=19192 sha256=a579072d01cbe4be3262cc38d5580a5843b81274911477bfb80f63cf81896202\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/e4/1d/06/640c93f5270d67d0247f30be91f232700d19023f9e66d735c7\n",
      "Successfully built fastai nvidia-ml-py3\n",
      "Installing collected packages: fastprogress, nvidia-ml-py3, murmurhash, cymem, plac, preshed, catalogue, srsly, wasabi, blis, thinc, spacy, dataclasses, fastai\n",
      "Successfully installed blis-0.4.1 catalogue-0.0.8 cymem-2.0.3 dataclasses-0.7 fastai-1.0.59 fastprogress-0.1.22 murmurhash-1.0.2 nvidia-ml-py3-7.352.0 plac-1.1.3 preshed-3.0.2 spacy-2.2.3 srsly-0.2.0 thinc-7.3.1 wasabi-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from platform import python_version\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp kaggle.json /home/azureuser/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/azureuser/.kaggle/kaggle.json'\n",
      "Downloading jigsaw-toxic-comment-classification-challenge.zip to /mnt/azmnt/code/Users/Wouter\n",
      " 77%|█████████████████████████████▉         | 41.0M/53.4M [00:00<00:00, 107MB/s]\n",
      "100%|██████████████████████████████████████| 53.4M/53.4M [00:01<00:00, 36.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open train.csv.zip, train.csv.zip.zip or train.csv.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "!unzip train.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip jigsaw-toxic-comment-classification-challenge.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data and create train, valid , test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df = df.sample(frac=1)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7ca72b5b9c688e9e</td>\n",
       "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c03f72fd8f8bf54f</td>\n",
       "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9e5b8e8fc1ff2e84</td>\n",
       "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5332799e706665a6</td>\n",
       "      <td>Pseudoscience category? \\n\\nI'm assuming that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfa7d8f0b4366680</td>\n",
       "      <td>(and if such phrase exists, it would be provid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  7ca72b5b9c688e9e  Geez, are you forgetful!  We've already discus...      0   \n",
       "1  c03f72fd8f8bf54f  Carioca RFA \\n\\nThanks for your support on my ...      0   \n",
       "2  9e5b8e8fc1ff2e84  \"\\n\\n Birthday \\n\\nNo worries, It's what I do ...      0   \n",
       "3  5332799e706665a6  Pseudoscience category? \\n\\nI'm assuming that ...      0   \n",
       "4  dfa7d8f0b4366680  (and if such phrase exists, it would be provid...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "103      1             1        1       0       1              0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "df.iloc[[103]][target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:10000].reset_index(drop=True)\n",
    "df_val = df[10000:11000].reset_index(drop=True)\n",
    "df_test = df[11000:13000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = transformers.BertModel\n",
    "tokenizer_class = transformers.BertTokenizer\n",
    "pretrained_weights='bert-base-uncased'# Load pretrained model/tokenizer\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "bert_model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq = 100\n",
    "def tokenize_text(df, max_seq):\n",
    "    return [\n",
    "        tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in df.comment_text.values\n",
    "    ]\n",
    "def pad_text(tokenized_text, max_seq):\n",
    "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])\n",
    "def tokenize_and_pad_text(df, max_seq):\n",
    "    tokenized_text = tokenize_text(df, max_seq)\n",
    "    padded_text = pad_text(tokenized_text, max_seq)\n",
    "    return torch.tensor(padded_text)\n",
    "def targets_to_tensor(df, target_columns):\n",
    "    return torch.tensor(df[target_columns].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1457 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (891 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1987 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1008 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (983 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1863 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (960 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (833 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (927 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (793 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1012 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (741 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (855 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (813 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (867 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1927 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (983 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (2829 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING - Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "train_indices = tokenize_and_pad_text(df_train, max_seq)\n",
    "val_indices = tokenize_and_pad_text(df_val, max_seq)\n",
    "test_indices = tokenize_and_pad_text(df_test, max_seq)\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_train = bert_model(train_indices)[0]  \n",
    "    x_val = bert_model(val_indices)[0]\n",
    "    x_test = bert_model(test_indices)[0]\n",
    "\n",
    "\n",
    "y_train = targets_to_tensor(df_train, target_columns)\n",
    "y_val = targets_to_tensor(df_val, target_columns)\n",
    "y_test = targets_to_tensor(df_test, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KimCNN(nn.Module):\n",
    "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):\n",
    "        \n",
    "        super(KimCNN, self).__init__()        \n",
    "        V = embed_num\n",
    "        D = embed_dim\n",
    "        C = class_num\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "        \n",
    "        self.static = static\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, D)) for K in Ks])\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.static:\n",
    "            x = Variable(x)   \n",
    "            \n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)        \n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)       \n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)        \n",
    "        x = torch.cat(x, 1)\n",
    "            \n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        output = self.sigmoid(logit)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('modelFullPerfect.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_num = x_train.shape[1]\n",
    "embed_dim = x_train.shape[2]\n",
    "class_num = y_train.shape[1]\n",
    "kernel_num = 3\n",
    "kernel_sizes = [2, 3, 4]\n",
    "dropout = 0.5\n",
    "static = True\n",
    "\n",
    "model = KimCNN(\n",
    "    embed_num=embed_num,\n",
    "    embed_dim=embed_dim,\n",
    "    class_num=class_num,\n",
    "    kernel_num=kernel_num,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    dropout=dropout,\n",
    "    static=static\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 10\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_data(x, y, batch_size):\n",
    "    i, batch = 0, 0\n",
    "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
    "        x_batch = x[i : i + batch_size]\n",
    "        y_batch = y[i : i + batch_size]\n",
    "        yield x_batch, y_batch, batch\n",
    "    if i + batch_size < len(x):\n",
    "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
    "    if batch == 0:\n",
    "        yield x, y, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train loss: 0.18. Validation loss: 0.09. Elapsed time: 16.68s.\n",
      "Epoch 2 Train loss: 0.11. Validation loss: 0.09. Elapsed time: 16.36s.\n",
      "Epoch 3 Train loss: 0.10. Validation loss: 0.08. Elapsed time: 16.20s.\n",
      "Epoch 4 Train loss: 0.10. Validation loss: 0.08. Elapsed time: 16.46s.\n",
      "Epoch 5 Train loss: 0.09. Validation loss: 0.07. Elapsed time: 16.46s.\n",
      "Epoch 6 Train loss: 0.08. Validation loss: 0.06. Elapsed time: 16.71s.\n",
      "Epoch 7 Train loss: 0.08. Validation loss: 0.06. Elapsed time: 16.60s.\n",
      "Epoch 8 Train loss: 0.08. Validation loss: 0.06. Elapsed time: 16.34s.\n",
      "Epoch 9 Train loss: 0.07. Validation loss: 0.06. Elapsed time: 16.58s.\n",
      "Epoch 10 Train loss: 0.07. Validation loss: 0.06. Elapsed time: 16.63s.\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0   \n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, batch_size):\n",
    "        y_pred = model(x_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= batch\n",
    "    train_losses.append(train_loss)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    model.eval() # disable dropout for deterministic output\n",
    "# deactivate autograd engine to reduce memory usage and speed up computations\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss, batch = 0, 1\n",
    "\n",
    "        for x_batch, y_batch, batch in generate_batch_data(x_val, y_val, batch_size):\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss /= batch\n",
    "        val_losses.append(val_loss)    \n",
    "    \n",
    "    print(\n",
    "        \"Epoch %d Train loss: %.2f. Validation loss: %.2f. Elapsed time: %.2fs.\"\n",
    "        % (epoch + 1, train_losses[-1], val_losses[-1], elapsed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Losses')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Losses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # disable dropout for deterministic output\n",
    "\n",
    "with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "    y_preds = []\n",
    "    batch = 0\n",
    "    for x_batch, y_batch, batch in generate_batch_data(x_test, y_test, batch_size):\n",
    "        y_pred = model(x_batch)\n",
    "        y_preds.extend(y_pred.cpu().numpy().tolist())\n",
    "    y_preds_np = np.array(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.001829e-05, 5.516882e-16, 1.346699e-06, 3.010653e-16, 4.295127e-07, 2.806820e-09],\n",
       "       [4.209973e-02, 8.148314e-06, 9.320569e-03, 2.959704e-06, 8.465828e-03, 4.489167e-04],\n",
       "       [7.182984e-04, 1.488052e-12, 5.755267e-05, 2.411508e-12, 2.279289e-05, 4.724144e-07],\n",
       "       [4.687427e-05, 3.110515e-15, 1.217899e-06, 7.214059e-16, 4.803255e-07, 3.237588e-09],\n",
       "       ...,\n",
       "       [4.342586e-04, 1.027305e-12, 3.102590e-05, 6.189098e-13, 1.467893e-05, 3.014703e-07],\n",
       "       [3.982232e-03, 1.863330e-09, 4.546963e-04, 9.714682e-10, 2.202663e-04, 9.563332e-06],\n",
       "       [8.692367e-05, 6.399820e-15, 3.437168e-06, 5.022165e-15, 1.106194e-06, 1.272415e-08],\n",
       "       [8.222843e-03, 3.297230e-08, 1.054609e-03, 1.434760e-08, 8.547234e-04, 2.918602e-05]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conMat = confusion_matrix(y_true=y_test.argmax(axis=1), y_pred=y_preds_np.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  72,    0,    0,    0,    0,    0],\n",
       "       [   1,    0,    0,    0,    0,    0],\n",
       "       [  26,    0,    0,    0,    0,    0],\n",
       "       [   2,    0,    0,    0,    0,    0],\n",
       "       [  82,    0,    0,    0,    0,    0],\n",
       "       [1817,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b32797240>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(conMat, index = [i for i in target_columns],\n",
    "                  columns = [i for i in target_columns])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_np = df_test[target_columns].values\n",
    "\n",
    "y_test_np[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>0.966242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>0.957392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>0.956408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>0.941863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>0.932632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>0.930836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label       auc\n",
       "1   severe_toxic  0.966242\n",
       "0          toxic  0.957392\n",
       "4         insult  0.956408\n",
       "2        obscene  0.941863\n",
       "3         threat  0.932632\n",
       "5  identity_hate  0.930836"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores = roc_auc_score(y_test_np, y_preds_np, average=None)\n",
    "df_accuracy = pd.DataFrame({\"label\": target_columns, \"auc\": auc_scores})\n",
    "df_accuracy.sort_values('auc')[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2201"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_labels = df_train[target_columns].sum().sum()\n",
    "positive_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = df_train[target_columns].count().sum()\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03668333333333333"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_labels/all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets = df_test[target_columns]\n",
    "df_pred_targets = pd.DataFrame(y_preds_np.round(), columns=target_columns, dtype=int)\n",
    "df_sanity = df_test_targets.join(df_pred_targets, how='inner', rsuffix='_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            186\n",
       "severe_toxic      17\n",
       "obscene           98\n",
       "threat             5\n",
       "insult            96\n",
       "identity_hate     18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_targets.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            121\n",
       "severe_toxic       0\n",
       "obscene           60\n",
       "threat             0\n",
       "insult            42\n",
       "identity_hate      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_targets.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df_sanity[df_sanity.toxic > 0][['toxic', 'toxic_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>toxic_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic  toxic_pred\n",
       "45        1           1\n",
       "53        1           1\n",
       "78        1           1\n",
       "82        1           1\n",
       "85        1           1\n",
       "135       1           1\n",
       "139       1           1\n",
       "161       1           1\n",
       "191       1           1\n",
       "203       1           1\n",
       "260       1           1\n",
       "265       1           1\n",
       "282       1           1\n",
       "290       1           1\n",
       "312       1           1\n",
       "329       1           1\n",
       "344       1           1\n",
       "383       1           1\n",
       "384       1           1\n",
       "411       1           1\n",
       "431       1           1\n",
       "475       1           1\n",
       "481       1           1\n",
       "484       1           1\n",
       "493       1           1\n",
       "528       1           1\n",
       "530       1           1\n",
       "533       1           1\n",
       "549       1           1\n",
       "571       1           1\n",
       "...     ...         ...\n",
       "1331      1           1\n",
       "1352      1           1\n",
       "1374      1           1\n",
       "1428      1           1\n",
       "1442      1           1\n",
       "1495      1           1\n",
       "1506      1           1\n",
       "1521      1           1\n",
       "1576      1           1\n",
       "1578      1           1\n",
       "1618      1           1\n",
       "1628      1           1\n",
       "1674      1           1\n",
       "1675      1           1\n",
       "1741      1           1\n",
       "1766      1           1\n",
       "1768      1           1\n",
       "1775      1           1\n",
       "1777      1           1\n",
       "1812      1           1\n",
       "1820      1           1\n",
       "1827      1           1\n",
       "1872      1           1\n",
       "1888      1           1\n",
       "1938      1           1\n",
       "1939      1           1\n",
       "1951      1           1\n",
       "1958      1           1\n",
       "1964      1           1\n",
       "1965      1           1\n",
       "\n",
       "[104 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.loc[l['toxic_pred'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './modelPerfect.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'modelFullPerfect.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('modelFull.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_single_text(text, max_seq):\n",
    "    return [\n",
    "        tokenizer.encode(text, add_special_tokens=True)[:max_seq] \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_text(tokenized_text, max_seq):\n",
    "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_pad_single_text(text, max_seq):\n",
    "    tokenized_text = tokenize_single_text(text, max_seq)\n",
    "    padded_text = pad_text(tokenized_text, max_seq)\n",
    "    return torch.tensor(padded_text)\n",
    "\n",
    "def targets_to_tensor(df, target_columns):\n",
    "    return torch.tensor(df[target_columns].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_indices = tokenize_and_pad_single_text(\"Kamil is a stupid ass hoe\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_mom = bert_model(mom_indices)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mom = targets_to_tensor(df_train, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9855, 0.1222, 0.8240, 0.0261, 0.6593, 0.1074]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT2.ipynb\t\t\t\t\t   models\r\n",
      "jigsaw-toxic-comment-classification-challenge.zip  modelSaved.pth\r\n",
      "kaggle.json\t\t\t\t\t   sample_submission.csv\r\n",
      "model2.pth\t\t\t\t\t   test.csv\r\n",
      "modelFull.pth\t\t\t\t\t   test_labels.csv\r\n",
      "modelPerfect.pth\t\t\t\t   train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
