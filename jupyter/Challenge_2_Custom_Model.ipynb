{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Challenge_2_Custom_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qibriH8m7Mz6",
        "pzAnVSeAVXVc"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "ef06cd19-66b6-46bc-bf45-184e12d3f7d4",
        "_uuid": "cca038ca9424a3f66e10262fc9129de807b5f855",
        "colab_type": "code",
        "id": "Or7NE9OYxY4B",
        "outputId": "1888d8ac-b0e7-4542-bbc2-2c0e0dc8224d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "from googleapiclient.discovery import build\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gq4Qvb1OyXp7",
        "outputId": "884b0dbe-41c5-4217-9b93-2d6e38ee5439",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4298e528-4149-4a1f-9423-667e00d89d16\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4298e528-4149-4a1f-9423-667e00d89d16\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle(1).json to kaggle(1).json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DdkcHupoyYm1",
        "colab": {}
      },
      "source": [
        "!mkdir /root/.kaggle/\n",
        "!cp kaggle.json /root/.kaggle/\n",
        "!rm kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GcRv-5wOXHAI",
        "outputId": "5e71a3b1-bb68-4fd2-8aa5-a559d118ba06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "!kaggle datasets download -d yliu9999/glove6b50d"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove6b50d.zip to /content\n",
            " 72% 49.0M/67.7M [00:02<00:02, 8.23MB/s]\n",
            "100% 67.7M/67.7M [00:02<00:00, 25.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ilm7OOwLya8V",
        "outputId": "037c2b8a-61c0-4b32-cd2a-f4a65b666859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 95% 25.0M/26.3M [00:00<00:00, 20.5MB/s]\n",
            "100% 26.3M/26.3M [00:00<00:00, 38.6MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 91.0MB/s]\n",
            "Downloading test_labels.csv.zip to /content\n",
            "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 212MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 38% 9.00M/23.4M [00:00<00:01, 11.8MB/s]\n",
            "100% 23.4M/23.4M [00:00<00:00, 32.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7CWDyQPp8_yn",
        "outputId": "f45098db-3432-4fbb-b80e-84e61b41ce7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!unzip glove6b50d.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove6b50d.zip\n",
            "  inflating: glove.6B.50d.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ra-t9J1m0mps",
        "outputId": "df988c5b-5950-40de-b674-16d574d6bd6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "!unzip test.csv.zip test.csv\n",
        "!unzip test_labels.csv.zip test_labels.csv\n",
        "!unzip train.csv.zip train.csv"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  test_labels.csv.zip\n",
            "  inflating: test_labels.csv         \n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T2ES3uwD1uA5",
        "outputId": "0683b424-b6f4-473a-b67b-c10a7474f43f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!unzip sample_submission.csv.zip sample_submission.csv"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "1c345d02-b768-491c-8c03-8c3459a552a8",
        "_uuid": "adbbfb0156952a6a43833e337b8a418ccac257aa",
        "colab_type": "code",
        "id": "5r6xk9RixY8R",
        "colab": {}
      },
      "source": [
        "path = './'\n",
        "EMBEDDING_FILE=f'{path}glove.6B.50d.txt'\n",
        "TRAIN_DATA_FILE=f'{path}train.csv'\n",
        "TEST_DATA_FILE=f'{path}test.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hcolPv4x8YRc",
        "colab": {}
      },
      "source": [
        "embed_size = 50 # how big is each word vector\n",
        "max_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 100 # max number of words in a comment to use"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GbPdBllk8dzu",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(TRAIN_DATA_FILE)\n",
        "test = pd.read_csv(TEST_DATA_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SCQoFiy6VFLG"
      },
      "source": [
        "# Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0ZMEkqR4_vqW",
        "colab": {}
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo_Iob1YFZB_",
        "colab": {}
      },
      "source": [
        "test.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acr5KmQMEop4",
        "colab": {}
      },
      "source": [
        "train.count() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9YnUXJPjLQcK",
        "colab": {}
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9QsxKOufPt7g",
        "colab": {}
      },
      "source": [
        "test.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G7Bap5XlPV3u"
      },
      "source": [
        "Dit deel gaat de meest bekende contractions veranderen hun voluit geschreven vorm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZOglb0bo_Tk2",
        "colab": {}
      },
      "source": [
        "# Get the values from the training and test set\n",
        "list_sentences_train = train[\"comment_text\"].fillna(\"_na_\").values\n",
        "list_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rvNozqYM8o8W",
        "outputId": "222c1e80-e7f2-4db8-f6d6-70bf668480f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "# Define the classes\n",
        "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "# Get the values from the training set\n",
        "y = train[list_classes].values\n",
        "y"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrVJtgG1JDrK",
        "colab_type": "text"
      },
      "source": [
        "Standard keras preprocessing, to turn each comment into a list of word indexes of equal length (with truncation or padding as needed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mylde4F8_qiK",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2FmxZdDq_xCS",
        "colab": {}
      },
      "source": [
        "??tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WAxEMOxD_qen",
        "colab": {}
      },
      "source": [
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bs7DaYL_65k4",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KiQidq-b_SuT",
        "colab": {}
      },
      "source": [
        "??pad_sequences()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W1-dpyfi6JxQ",
        "colab": {}
      },
      "source": [
        "X_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JC5liiWj65nx",
        "colab": {}
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qibriH8m7Mz6"
      },
      "source": [
        "## Contradictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8ylVFYE3LdUD",
        "colab": {}
      },
      "source": [
        "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XxEas8T7MCCm",
        "colab": {}
      },
      "source": [
        "def _get_contractions(contraction_dict):\n",
        "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
        "    return contraction_dict, contraction_re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yRc3f4QJMFcC",
        "colab": {}
      },
      "source": [
        "contractions, contractions_re = _get_contractions(contraction_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DulIAGbtMMAF",
        "colab": {}
      },
      "source": [
        "def replace_contractions(text):\n",
        "    def replace(match):\n",
        "        return contractions[match.group(0)]\n",
        "    return contractions_re.sub(replace, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "efP-4O79MNQ3",
        "colab": {}
      },
      "source": [
        "train_comment_list = train['comment_text'].values\n",
        "list_train_no_contractions = []\n",
        "for item in train_comment_list:\n",
        "  list_train_no_contractions.append(replace_contractions(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ILpgGbwtP30H",
        "colab": {}
      },
      "source": [
        "test_comment_list = test['comment_text'].values\n",
        "list_test_no_contractions = []\n",
        "for item in test_comment_list:\n",
        "  list_test_no_contractions.append(replace_contractions(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "opdYN12HOyYX",
        "colab": {}
      },
      "source": [
        "train['comment_text'] = list_train_no_contractions\n",
        "test['comment_text'] = list_test_no_contractions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLk4gt58PL7_",
        "outputId": "c9913092-993f-4a72-ddfe-b95c32723561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I am ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I am really not trying to edit war. I...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI cannot make any real suggestions on...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "5  00025465d4725e87  ...             0\n",
              "6  0002bcb3da6cb337  ...             0\n",
              "7  00031b1e95af7921  ...             0\n",
              "8  00037261f536c51d  ...             0\n",
              "9  00040093b2687caa  ...             0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RawuoH1zQZJd",
        "outputId": "d6bfa724-f1f9-4b12-b39e-f15cc65c3966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I do not anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text\n",
              "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you wi...\n",
              "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4  00017695ad8997eb         I do not anonymously edit articles at all."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8c6wHWo0RhF5"
      },
      "source": [
        "Hier worden verkeerd geschreven woorden eruit gehaald worden aub de googleNews vectors niet lokaal downloaden 1.5GB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pzAnVSeAVXVc"
      },
      "source": [
        "## Spelling controle \n",
        "### Heeft geen meerwaarde want schrijffouten kunnen bepalen of de comment toxic is of niet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rz3ISmIQRmBR",
        "colab": {}
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sG2FD286Upul",
        "colab": {}
      },
      "source": [
        "!gunzip GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PKbwRfTVVyIK",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import gensim\n",
        "import heapq\n",
        "from operator import itemgetter\n",
        "from multiprocessing import Pool"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TdcxHslzVzvj",
        "outputId": "a52d72ca-2187-4b7d-a263-0adc73665693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ScCeVQ3FV93t",
        "colab": {}
      },
      "source": [
        "words = model.index2word\n",
        "w_rank = {}\n",
        "for i,word in enumerate(words):\n",
        "    w_rank[word] = i\n",
        "WORDS = w_rank"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ECFRt1_WHtw",
        "colab": {}
      },
      "source": [
        "def words(text): return re.findall(r'\\w+', text.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d35l5yM_WW0G",
        "colab": {}
      },
      "source": [
        "def P(word): \n",
        "    \"Probability of `word`.\"\n",
        "    # use inverse of rank as proxy\n",
        "    # returns 0 if the word isn't in the dictionary\n",
        "    return - WORDS.get(word, 0)\n",
        "\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r23cJPtoWaI3",
        "colab": {}
      },
      "source": [
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
        "\n",
        "def build_vocab(texts):\n",
        "    sentences = texts.apply(lambda x: x.split()).values\n",
        "    vocab = {}\n",
        "    for sentence in sentences:\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except KeyError:\n",
        "                vocab[word] = 1\n",
        "    return vocab\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iiLzRF8rWc1D",
        "colab": {}
      },
      "source": [
        "vocab = build_vocab(train.comment_text)\n",
        "dicts_corrected_words = []\n",
        "top_90k_words = dict(heapq.nlargest(90000, vocab.items(), key=itemgetter(1)))\n",
        "\n",
        "pool = Pool(4)\n",
        "corrected_words = pool.map(correction,list(top_90k_words.keys()))\n",
        "\n",
        "for word,corrected_word in zip(top_90k_words,corrected_words):\n",
        "    if word!=corrected_word:\n",
        "        dicts_corrected_words.append({word: corrected_word})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YQNwl6JuWgnP",
        "outputId": "8eedd3cc-41f5-4994-c351-88eb827de1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dicts_corrected_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'to': 'two'},\n",
              " {'of': 'on'},\n",
              " {'and': 'an'},\n",
              " {'a': 'at'},\n",
              " {'\"': 's'},\n",
              " {'-': 's'},\n",
              " {'page.': 'page'},\n",
              " {'article.': 'article'},\n",
              " {'you.': 'you'},\n",
              " {',': 's'},\n",
              " {'Wikipedia.': 'Wikipedia'},\n",
              " {'.': 's'},\n",
              " {'(UTC)': 'UTC'},\n",
              " {'article,': 'article'},\n",
              " {'page,': 'page'},\n",
              " {'it,': 'it'},\n",
              " {'|': 's'},\n",
              " {'me.': 'me'},\n",
              " {'here.': 'here'},\n",
              " {')': 's'},\n",
              " {'—': 's'},\n",
              " {'you,': 'you'},\n",
              " {'However,': 'However'},\n",
              " {'(talk)': 'talk'},\n",
              " {'that.': 'that'},\n",
              " {'Also,': 'Also'},\n",
              " {'this.': 'this'},\n",
              " {'me,': 'me'},\n",
              " {'Wikipedia,': 'Wikipedia'},\n",
              " {'that,': 'that'},\n",
              " {'this,': 'this'},\n",
              " {'(and': 'hand'},\n",
              " {\"Wikipedia's\": 'Wikipedians'},\n",
              " {'here,': 'here'},\n",
              " {'is,': 'is'},\n",
              " {'Thanks.': 'Thanks'},\n",
              " {'editing.': 'editing'},\n",
              " {'not.': 'not'},\n",
              " {'articles.': 'articles'},\n",
              " {'there.': 'there'},\n",
              " {'so,': 'so'},\n",
              " {'–': 's'},\n",
              " {'...': 'in.'},\n",
              " {'now.': 'now'},\n",
              " {'do.': 'do'},\n",
              " {'(I': 'I'},\n",
              " {'pages,': 'pages'},\n",
              " {'\"\"The': 'The'},\n",
              " {'Hello,': 'Hello'},\n",
              " {'(or': 'for'},\n",
              " {'deletion,': 'deletion'},\n",
              " {'articles,': 'articles'},\n",
              " {'(talk': 'talk'},\n",
              " {'(': 's'},\n",
              " {'Wikipedia!': 'Wikipedia'},\n",
              " {'way,': 'way'},\n",
              " {'?': 's'},\n",
              " {'sources.': 'sources'},\n",
              " {'again,': 'again'},\n",
              " {'time,': 'time'},\n",
              " {\"article's\": 'articles'},\n",
              " {'Again,': 'Again'},\n",
              " {'encyclopedia.': 'encyclopedia'},\n",
              " {'is.': 'is'},\n",
              " {'all.': 'all'},\n",
              " {'too.': 'too'},\n",
              " {'deleted.': 'deleted'},\n",
              " {'deletion.': 'deletion'},\n",
              " {'it?': 'it'},\n",
              " {'vandalism.': 'vandalism'},\n",
              " {'removed.': 'removed'},\n",
              " {'/': 's'},\n",
              " {'not,': 'not'},\n",
              " {'Yes,': 'Yes'},\n",
              " {'now,': 'now'},\n",
              " {'(which': 'which'},\n",
              " {'information.': 'information'},\n",
              " {'case,': 'case'},\n",
              " {'Hi,': 'His'},\n",
              " {'Well,': 'Well'},\n",
              " {'you?': 'you'},\n",
              " {'REDIRECT': 'DIRECT'},\n",
              " {'one.': 'one'},\n",
              " {'them,': 'them'},\n",
              " {'source.': 'source'},\n",
              " {'example,': 'example'},\n",
              " {'all,': 'all'},\n",
              " {'up.': 'up'},\n",
              " {'So,': 'So'},\n",
              " {'date.': 'date'},\n",
              " {'contribs)': 'contries'},\n",
              " {'!': 's'},\n",
              " {'content,': 'content'},\n",
              " {'edits,': 'edits'},\n",
              " {'fact,': 'fact'},\n",
              " {'edits.': 'edits'},\n",
              " {'there,': 'there'},\n",
              " {'section.': 'section'},\n",
              " {'help,': 'help'},\n",
              " {'however,': 'however'},\n",
              " {'out.': 'out'},\n",
              " {'yourself,': 'yourself'},\n",
              " {'Thanks,': 'Thanks'},\n",
              " {'sources,': 'sources'},\n",
              " {'people,': 'people'},\n",
              " {'10': '1'},\n",
              " {'way.': 'way'},\n",
              " {'(see': 'see'},\n",
              " {'(the': 'the'},\n",
              " {'(as': 'was'},\n",
              " {'him.': 'him'},\n",
              " {'work.': 'work'},\n",
              " {'know,': 'know'},\n",
              " {'faggot': 'fagot'},\n",
              " {'information,': 'information'},\n",
              " {'pages.': 'pages'},\n",
              " {'said,': 'said'},\n",
              " {'24': '2'},\n",
              " {'wrong.': 'wrong'},\n",
              " {'contributions.': 'contributions'},\n",
              " {'source,': 'source'},\n",
              " {'guidelines.': 'guidelines'},\n",
              " {'you!': 'you'},\n",
              " {'yourself.': 'yourself'},\n",
              " {'on.': 'on'},\n",
              " {'discussion.': 'discussion'},\n",
              " {'\"\"the': 'the'},\n",
              " {'(Talk)': 'Talk'},\n",
              " {'No,': 'No'},\n",
              " {'stop.': 'stop'},\n",
              " {'WANKER': 'WANE'},\n",
              " {'well,': 'well'},\n",
              " {'use.': 'use'},\n",
              " {'NPOV': 'NOV'},\n",
              " {'\"\"': 'in'},\n",
              " {'course,': 'course'},\n",
              " {'one,': 'one'},\n",
              " {'name.': 'name'},\n",
              " {'policy.': 'policy'},\n",
              " {'help.': 'help'},\n",
              " {'section,': 'section'},\n",
              " {'up,': 'up'},\n",
              " {'\"\"I': 'I'},\n",
              " {'stay.': 'stay'},\n",
              " {'20': '2'},\n",
              " {'Thanks!': 'Thanks'},\n",
              " {'|-': 'in'},\n",
              " {'yourself!': 'yourself'},\n",
              " {'wikipedia.': 'wikipedia'},\n",
              " {'welcome!': 'welcome'},\n",
              " {'know.': 'know'},\n",
              " {'article?': 'article'},\n",
              " {'ass.': 'ass'},\n",
              " {'notable,': 'notable'},\n",
              " {'Anyway,': 'Anyway'},\n",
              " {'here:': 'here'},\n",
              " {'say,': 'says'},\n",
              " {'(in': 'in'},\n",
              " {'edit.': 'edit'},\n",
              " {'content.': 'content'},\n",
              " {'edit,': 'edit'},\n",
              " {'{|': 'in'},\n",
              " {'point.': 'points'},\n",
              " {'questions,': 'questions'},\n",
              " {'page?': 'page'},\n",
              " {'question.': 'question'},\n",
              " {'to.': 'top'},\n",
              " {'this?': 'this'},\n",
              " {'problem.': 'problem'},\n",
              " {'Wikipedian!': 'Wikipedians'},\n",
              " {'above,': 'above'},\n",
              " {'issue.': 'issue'},\n",
              " {'name,': 'name'},\n",
              " {'do,': 'do'},\n",
              " {'link.': 'link'},\n",
              " {'blocked.': 'blocked'},\n",
              " {'thing.': 'things'},\n",
              " {'policy,': 'policy'},\n",
              " {'Oh,': 'Oh'},\n",
              " {'case.': 'case'},\n",
              " {'discussion,': 'discussion'},\n",
              " {'right.': 'right'},\n",
              " {'above.': 'above'},\n",
              " {'out,': 'out'},\n",
              " {'history.': 'history'},\n",
              " {'and/or': 'andor'},\n",
              " {'yes,': 'yes'},\n",
              " {'though.': 'though'},\n",
              " {'Cheers,': 'Cheers'},\n",
              " {'12': '1'},\n",
              " {'-)': 'in'},\n",
              " {'others.': 'others'},\n",
              " {'person,': 'person'},\n",
              " {'(not': 'not'},\n",
              " {'editors.': 'editors'},\n",
              " {'about.': 'about'},\n",
              " {'and,': 'ands'},\n",
              " {'Now,': 'Now'},\n",
              " {'this:': 'this'},\n",
              " {'15': '1'},\n",
              " {'work,': 'work'},\n",
              " {'faggots': 'maggots'},\n",
              " {'him,': 'him'},\n",
              " {'that?': 'that'},\n",
              " {'place.': 'place'},\n",
              " {'though,': 'though'},\n",
              " {'me?': 'me'},\n",
              " {'right,': 'right'},\n",
              " {'history,': 'history'},\n",
              " {'worked,': 'worked'},\n",
              " {'life.': 'life'},\n",
              " {'30': '3'},\n",
              " {'point,': 'points'},\n",
              " {'(just': 'just'},\n",
              " {'in,': 'in'},\n",
              " {'fucksex': 'fucked'},\n",
              " {'yourselfgo': 'yourself'},\n",
              " {\"subject's\": 'subjects'},\n",
              " {'teabag,': 'teabag'},\n",
              " {'are.': 'are'},\n",
              " {'site.': 'site'},\n",
              " {'[': 's'},\n",
              " {'list.': 'list'},\n",
              " {'are,': 'are'},\n",
              " {'wrong,': 'wrong'},\n",
              " {'AfD': 'AD'},\n",
              " {'sandbox.': 'sandbox'},\n",
              " {'subject,': 'subject'},\n",
              " {'to,': 'top'},\n",
              " {'then,': 'then'},\n",
              " {'either.': 'either'},\n",
              " {'back.': 'back'},\n",
              " {'position.': 'position'},\n",
              " {'true.': 'true'},\n",
              " {'better.': 'better'},\n",
              " {'opinion,': 'opinion'},\n",
              " {'opinion.': 'opinion'},\n",
              " {'(it': 'it'},\n",
              " {'thing,': 'things'},\n",
              " {'Regards,': 'Regards'},\n",
              " {'be.': 'be'},\n",
              " {'11': '1'},\n",
              " {'questions.': 'questions'},\n",
              " {'day.': 'day'},\n",
              " {'else.': 'else'},\n",
              " {'anything.': 'anything'},\n",
              " {'\",': 'in'},\n",
              " {'FUCKER': 'FUCK'},\n",
              " {'14': '1'},\n",
              " {'Barnstar': 'Branstad'},\n",
              " {'things.': 'things'},\n",
              " {'25': '2'},\n",
              " {'references.': 'references'},\n",
              " {'Sorry,': 'Sorry'},\n",
              " {'address,': 'address'},\n",
              " {'You!': 'You'},\n",
              " {'experiment,': 'experiment'},\n",
              " {'subject.': 'subject'},\n",
              " {'fact.': 'fact'},\n",
              " {'Yeah,': 'Yeah'},\n",
              " {'done.': 'done'},\n",
              " {'company,': 'company'},\n",
              " {'words,': 'words'},\n",
              " {'Hey,': 'Hey'},\n",
              " {'—Preceding': 'Preceding'},\n",
              " {'position,': 'position'},\n",
              " {'Hi.': 'His'},\n",
              " {'deleted,': 'deleted'},\n",
              " {'16': '1'},\n",
              " {'vandalism,': 'vandalism'},\n",
              " {'Re:': 'Red'},\n",
              " {'correct.': 'correct'},\n",
              " {'comments.': 'comments'},\n",
              " {'consensus.': 'consensus'},\n",
              " {'ago.': 'ago'},\n",
              " {'on,': 'on'},\n",
              " {'anyway.': 'anyway'},\n",
              " {'view.': 'view'},\n",
              " {'matter.': 'matter'},\n",
              " {'notable.': 'notable'},\n",
              " {'behaviour': 'behavior'},\n",
              " {'too,': 'too'},\n",
              " {'question,': 'question'},\n",
              " {'true,': 'true'},\n",
              " {'shit.': 'shit'},\n",
              " {'good.': 'good'},\n",
              " {'topic.': 'topic'},\n",
              " {'POV.': 'POV'},\n",
              " {'block.': 'block'},\n",
              " {'OK,': 'OK'},\n",
              " {'infobox': 'inbox'},\n",
              " {'Actually,': 'Actually'},\n",
              " {'editing!': 'editing'},\n",
              " {'(you': 'you'},\n",
              " {'editors,': 'editors'},\n",
              " {'war.': 'war'},\n",
              " {'MOTHJER': 'MOTHER'},\n",
              " {'years,': 'years'},\n",
              " {'us.': 'us'},\n",
              " {'18': '1'},\n",
              " {'ago,': 'ago'},\n",
              " {'first.': 'first'},\n",
              " {'website.': 'website'},\n",
              " {'17': '1'},\n",
              " {'use,': 'use'},\n",
              " {'sense.': 'sense'},\n",
              " {'before,': 'before'},\n",
              " {'with.': 'with'},\n",
              " {'process.': 'process'},\n",
              " {'aRe': 'are'},\n",
              " {'FGGT!': 'FGG'},\n",
              " {'23': '2'},\n",
              " {'comment.': 'comment'},\n",
              " {'Welcome!': 'Welcome'},\n",
              " {'reason.': 'reason'},\n",
              " {'person.': 'person'},\n",
              " {'here?': 'here'},\n",
              " {'13': '1'},\n",
              " {'(a': 'la'},\n",
              " {'myself.': 'myself'},\n",
              " {'contribs': 'contries'},\n",
              " {'research.': 'research'},\n",
              " {'did.': 'did'},\n",
              " {'it!': 'it'},\n",
              " {\"Here's\": \"Here'sa\"},\n",
              " {'website,': 'website'},\n",
              " {'100': '1'},\n",
              " {'material.': 'material'},\n",
              " {'media,': 'media'},\n",
              " {'message.': 'message'},\n",
              " {'error,': 'error'},\n",
              " {'(if': 'if'},\n",
              " {'itself.': 'itself'},\n",
              " {'poop.': 'poop'},\n",
              " {'NOOBS': 'NBS'},\n",
              " {'possible.': 'possible'},\n",
              " {'(for': 'for'},\n",
              " {'Furthermore,': 'Furthermore'},\n",
              " {'wikipedia,': 'wikipedia'},\n",
              " {'much.': 'much'},\n",
              " {'day,': 'day'},\n",
              " {'before.': 'before'},\n",
              " {'right?': 'right'},\n",
              " {'site,': 'site'},\n",
              " {'others,': 'others'},\n",
              " {'future.': 'future'},\n",
              " {'But,': 'But'},\n",
              " {'issue,': 'issue'},\n",
              " {'view,': 'view'},\n",
              " {'off.': 'off'},\n",
              " {'account.': 'account'},\n",
              " {'facts.': 'facts'},\n",
              " {'days.': 'days'},\n",
              " {'i.e.': 'ie.'},\n",
              " {'3RR': 'RR'},\n",
              " {'text.': 'text'},\n",
              " {'helpful:': 'helpful'},\n",
              " {'enough.': 'enough'},\n",
              " {'2)': '2'},\n",
              " {'say.': 'says'},\n",
              " {'language.': 'language'},\n",
              " {\"'image'\": 'image'},\n",
              " {'thanks.': 'thanks'},\n",
              " {'editor,': 'editor'},\n",
              " {'1)': '1'},\n",
              " {'hand,': 'hand'},\n",
              " {'rules.': 'rules'},\n",
              " {'else,': 'else'},\n",
              " {'Please,': 'Please'},\n",
              " {'life,': 'life'},\n",
              " {'days,': 'days'},\n",
              " {'sites,': 'sites'},\n",
              " {'things,': 'things'},\n",
              " {'editor.': 'editor'},\n",
              " {'see,': 'see'},\n",
              " {'Finally,': 'Finally'},\n",
              " {'myself,': 'myself'},\n",
              " {'anything,': 'anything'},\n",
              " {'Unfortunately,': 'Unfortunately'},\n",
              " {'appreciated.': 'appreciated'},\n",
              " {'reason,': 'reason'},\n",
              " {'for.': 'for'},\n",
              " {'27': '2'},\n",
              " {'template.': 'template'},\n",
              " {'project.': 'project'},\n",
              " {'process,': 'process'},\n",
              " {'delay.': 'delay'},\n",
              " {'19': '1'},\n",
              " {'editing,': 'editing'},\n",
              " {'band,': 'band'},\n",
              " {'world,': 'world'},\n",
              " {'truth.': 'truth'},\n",
              " {'attacks.': 'attacks'},\n",
              " {'Therefore,': 'Therefore'},\n",
              " {'something.': 'something'},\n",
              " {'YOU,': 'YOU'},\n",
              " {'policies.': 'policies'},\n",
              " {'\"\"a': 'via'},\n",
              " {'contributions,': 'contributions'},\n",
              " {'21': '1'},\n",
              " {'times.': 'times'},\n",
              " {'please.': 'pleased'},\n",
              " {'UP!': 'UP'},\n",
              " {'problem,': 'problem'},\n",
              " {'attack.': 'attack'},\n",
              " {'instead.': 'instead'},\n",
              " {'links.': 'links'},\n",
              " {'yet.': 'yet'},\n",
              " {'like.': 'like'},\n",
              " {'reference.': 'reference'},\n",
              " {'Ok,': 'Ok'},\n",
              " {'hitler!': 'hitler'},\n",
              " {'be,': 'be'},\n",
              " {'times,': 'times'},\n",
              " {'And,': 'And'},\n",
              " {'22': '2'},\n",
              " {'(with': 'with'},\n",
              " {'issues.': 'issues'},\n",
              " {'review.': 'review'},\n",
              " {'Hello.': 'Hello'},\n",
              " {'users,': 'users'},\n",
              " {'reverted,': 'reverted'},\n",
              " {'encyclopedia,': 'encyclopedia'},\n",
              " {'no,': 'not'},\n",
              " {'tag),': 'tag'},\n",
              " {'sorry,': 'sorry'},\n",
              " {'\"==': '=='},\n",
              " {'then.': 'then'},\n",
              " {'status.': 'status'},\n",
              " {'(but': 'but'},\n",
              " {'appropriate.': 'appropriate'},\n",
              " {'back,': 'back'},\n",
              " {'user,': 'users'},\n",
              " {'users.': 'users'},\n",
              " {'BeCauSe': 'Because'},\n",
              " {').': 'v.'},\n",
              " {'image.': 'image'},\n",
              " {'book,': 'book'},\n",
              " {'account,': 'account'},\n",
              " {'BOOBS,': 'BOOBS'},\n",
              " {'(i.e.': 'ie.'},\n",
              " {'what?': 'what'},\n",
              " {'fine.': 'fine'},\n",
              " {'words.': 'words'},\n",
              " {'26': '2'},\n",
              " {'used.': 'used'},\n",
              " {'place,': 'place'},\n",
              " {'evidence.': 'evidence'},\n",
              " {'user.': 'users'},\n",
              " {'alone.': 'alone'},\n",
              " {'instance,': 'instance'},\n",
              " {'nikko': 'nikki'},\n",
              " {'references,': 'references'},\n",
              " {'good,': 'good'},\n",
              " {'mean,': 'means'},\n",
              " {'28': '2'},\n",
              " {'first,': 'first'},\n",
              " {'RfC': 'RC'},\n",
              " {'made.': 'made'},\n",
              " {'reverted.': 'reverted'},\n",
              " {'idea.': 'idea'},\n",
              " {'blocked,': 'blocked'},\n",
              " {'\"I': 'I'},\n",
              " {'summary.': 'summary'},\n",
              " {'created,': 'created'},\n",
              " {'correct,': 'correct'},\n",
              " {'club,': 'club'},\n",
              " {'e.g.': 'eg.'},\n",
              " {'didnt': 'didn'},\n",
              " {'note,': 'noted'},\n",
              " {'text,': 'text'},\n",
              " {'was,': 'was'},\n",
              " {'version.': 'version'},\n",
              " {'later.': 'later'},\n",
              " {'warning.': 'warning'},\n",
              " {'Okay,': 'Okay'},\n",
              " {'down.': 'down'},\n",
              " {'did,': 'did'},\n",
              " {'research,': 'research'},\n",
              " {'off,': 'off'},\n",
              " {'changes.': 'changes'},\n",
              " {'\"\"In': 'In'},\n",
              " {'change.': 'change'},\n",
              " {'list,': 'list'},\n",
              " {'language,': 'language'},\n",
              " {'YOU!': 'YOU'},\n",
              " {'box.': 'box'},\n",
              " {'niggas!': 'niggas'},\n",
              " {'matter,': 'matter'},\n",
              " {'done,': 'done'},\n",
              " {'sexSex': 'sexes'},\n",
              " {'1,': '1'},\n",
              " {'article:': 'article'},\n",
              " {'topic,': 'topic'},\n",
              " {'50': '5'},\n",
              " {'mind.': 'mind'},\n",
              " {'(like': 'like'},\n",
              " {'field.': 'field'},\n",
              " {'facts,': 'facts'},\n",
              " {'know?': 'know'},\n",
              " {'altered,': 'altered'},\n",
              " {'English.': 'English'},\n",
              " {'more,': 'more'},\n",
              " {'(that': 'that'},\n",
              " {'agree.': 'agreed'},\n",
              " {'image,': 'image'},\n",
              " {'First,': 'First'},\n",
              " {'Cheers.': 'Cheers'},\n",
              " {'same.': 'same'},\n",
              " {'like,': 'like'},\n",
              " {'comments,': 'comments'},\n",
              " {'}}': 'in'},\n",
              " {'so-called': 'socalled'},\n",
              " {'with,': 'with'},\n",
              " {'(Talk': 'Talk'},\n",
              " {'companies.': 'companies'},\n",
              " {'other.': 'other'},\n",
              " {'addition,': 'addition'},\n",
              " {'already.': 'already'},\n",
              " {'book.': 'book'},\n",
              " {'\"\"my': 'my'},\n",
              " {'faith.': 'faith'},\n",
              " {'(The': 'The'},\n",
              " {'userpage': 'username'},\n",
              " {'BTW,': 'BTW'},\n",
              " {'anyway,': 'anyway'},\n",
              " {'English,': 'English'},\n",
              " {\"user's\": 'users'},\n",
              " {'LAWDY.': 'LADY'},\n",
              " {'ALL!!': 'ALL'},\n",
              " {'war,': 'war'},\n",
              " {'admin.': 'admin'},\n",
              " {'e-mail': 'email'},\n",
              " {'think.': 'think'},\n",
              " {'block,': 'block'},\n",
              " {'comment,': 'comment'},\n",
              " {'understand.': 'understand'},\n",
              " {'anymore.': 'anymore'},\n",
              " {'nonsense.': 'nonsense'},\n",
              " {'community.': 'community'},\n",
              " {'please,': 'pleased'},\n",
              " {'me)': 'me'},\n",
              " {'about,': 'about'},\n",
              " {'involved.': 'involved'},\n",
              " {'link,': 'link'},\n",
              " {'man,': 'many'},\n",
              " {'needed.': 'needed'},\n",
              " {'I,': 'I'},\n",
              " {'soon.': 'soon'},\n",
              " {'penis,': 'penis'},\n",
              " {'barnstar': 'barista'},\n",
              " {'29': '2'},\n",
              " {'asshole.': 'asshole'},\n",
              " {'have.': 'have'},\n",
              " {'such,': 'such'},\n",
              " {'request.': 'request'},\n",
              " {'itself,': 'itself'},\n",
              " {'title.': 'title'},\n",
              " {'biographies,': 'biographies'},\n",
              " {'criteria.': 'criteria'},\n",
              " {'faith,': 'faith'},\n",
              " {'Moreover,': 'Moreover'},\n",
              " {'consensus,': 'consensus'},\n",
              " {'but,': 'but'},\n",
              " {'doesnt': 'doesn'},\n",
              " {'much,': 'much'},\n",
              " {'year,': 'year'},\n",
              " {'not?': 'not'},\n",
              " {'tag.': 'tag'},\n",
              " {'exist.': 'exist'},\n",
              " {'Cheers!': 'Cheers'},\n",
              " {'(including': 'including'},\n",
              " {'future,': 'future'},\n",
              " {'created.': 'created'},\n",
              " {'also,': 'also'},\n",
              " {'statement.': 'statement'},\n",
              " {'see.': 'see'},\n",
              " {'(such': 'such'},\n",
              " {'//': 'in'},\n",
              " {'bands,': 'bands'},\n",
              " {'think,': 'think'},\n",
              " {'admin-': 'admin'},\n",
              " {'talkpage': 'tankage'},\n",
              " {'away.': 'away'},\n",
              " {'Second,': 'Second'},\n",
              " {'interest.': 'interest'},\n",
              " {'links,': 'links'},\n",
              " {'POV,': 'POV'},\n",
              " {'context.': 'context'},\n",
              " {'page:': 'page'},\n",
              " {'to:': 'top'},\n",
              " {'uploaded,': 'uploaded'},\n",
              " {'is:': 'is'},\n",
              " {'go.': 'go'},\n",
              " {'such.': 'such'},\n",
              " {'gay!': 'gay'},\n",
              " {'mind,': 'mind'},\n",
              " {'of.': 'off'},\n",
              " {'system.': 'system'},\n",
              " {'below,': 'below'},\n",
              " {'today,': 'today'},\n",
              " {'31': '1'},\n",
              " {'was.': 'was'},\n",
              " {'entry),': 'entry'},\n",
              " {'reply.': 'reply'},\n",
              " {'enough,': 'enough'},\n",
              " {'term.': 'term'},\n",
              " {'\"\"What': 'What'},\n",
              " {'sense,': 'sense'},\n",
              " {'incorrect.': 'incorrect'},\n",
              " {'welcome.': 'welcome'},\n",
              " {'\"\"A': 'A'},\n",
              " {'word.': 'words'},\n",
              " {'removed,': 'removed'},\n",
              " {'have,': 'have'},\n",
              " {'least,': 'least'},\n",
              " {'(at': 'at'},\n",
              " {'better,': 'better'},\n",
              " {'(though': 'though'},\n",
              " {'yet,': 'yet'},\n",
              " {'material,': 'material'},\n",
              " {'area.': 'area'},\n",
              " {'stuff.': 'stuff'},\n",
              " {'agree,': 'agreed'},\n",
              " {'now?': 'now'},\n",
              " {'man.': 'many'},\n",
              " {'reasons.': 'reasons'},\n",
              " {'around.': 'around'},\n",
              " {'useful.': 'useful'},\n",
              " {'Otherwise,': 'Otherwise'},\n",
              " {'can.': 'can'},\n",
              " {'(e.g.': 'eg.'},\n",
              " {'tagging.': 'tagging'},\n",
              " {'example.': 'example'},\n",
              " {'(even': 'even'},\n",
              " {'Additionally,': 'Additionally'},\n",
              " {'fine,': 'fine'},\n",
              " {'banned.': 'banned'},\n",
              " {'best,': 'best'},\n",
              " {'RfA': 'RA'},\n",
              " {'contributions\"\"': 'contributions'},\n",
              " {'admin,': 'admin'},\n",
              " {'possible,': 'possible'},\n",
              " {'her.': 'her'},\n",
              " {'group,': 'group'},\n",
              " {'think?': 'think'},\n",
              " {'reference,': 'reference'},\n",
              " {'want.': 'want'},\n",
              " {'of,': 'off'},\n",
              " {'\"\"This': 'This'},\n",
              " {'notable:': 'notable'},\n",
              " {'notability.': 'notability'},\n",
              " {'shit,': 'shit'},\n",
              " {'argument.': 'argument'},\n",
              " {'own.': 'own'},\n",
              " {'something,': 'something'},\n",
              " {'says,': 'says'},\n",
              " {'||': 'in'},\n",
              " {'changes,': 'changes'},\n",
              " {'attacks,': 'attacks'},\n",
              " {'template,': 'template'},\n",
              " {'Wikipedia?': 'Wikipedia'},\n",
              " {'rules,': 'rules'},\n",
              " {'don’t': 'dont'},\n",
              " {'mine.': 'mine'},\n",
              " {'rule.': 'rules'},\n",
              " {'situation.': 'situation'},\n",
              " {'realise': 'realize'},\n",
              " {'info.': 'info'},\n",
              " {'response.': 'response'},\n",
              " {'later,': 'later'},\n",
              " {'books,': 'books'},\n",
              " {'images,': 'images'},\n",
              " {'why.': 'why'},\n",
              " {'which,': 'which'},\n",
              " {'issues,': 'issues'},\n",
              " {'picture,': 'picture'},\n",
              " {'about?': 'about'},\n",
              " {'version,': 'version'},\n",
              " {'(although': 'although'},\n",
              " {'Secondly,': 'Secondly'},\n",
              " {'period.': 'period'},\n",
              " {'them?': 'them'},\n",
              " {'made,': 'made'},\n",
              " {'names,': 'names'},\n",
              " {'in),': 'in'},\n",
              " {'notice,': 'notice'},\n",
              " {'works.': 'works'},\n",
              " {'also.': 'also'},\n",
              " {'Why?': 'Why'},\n",
              " {'game.': 'game'},\n",
              " {'attack,': 'attack'},\n",
              " {'project,': 'project'},\n",
              " {'mistake.': 'mistake'},\n",
              " {'bias.': 'bias'},\n",
              " {'nothing.': 'nothing'},\n",
              " {'2,': '2'},\n",
              " {'citations.': 'citations'},\n",
              " {'record,': 'record'},\n",
              " {'(to': 'ito'},\n",
              " {'sentence.': 'sentence'},\n",
              " {'themselves.': 'themselves'},\n",
              " {'isnt': 'int'},\n",
              " {'involvement.': 'involvement'},\n",
              " {'together.': 'together'},\n",
              " {'clear.': 'clear'},\n",
              " {'do?': 'do'},\n",
              " {'Thus,': 'Thus'},\n",
              " {'ArbCom': 'Arbor'},\n",
              " {'evidence,': 'evidence'},\n",
              " {'claim.': 'claims'},\n",
              " {'other,': 'other'},\n",
              " {'problems.': 'problems'},\n",
              " {'Or,': 'Or'},\n",
              " {'48': '4'},\n",
              " {'Hi!': 'His'},\n",
              " {'administrator.': 'administrators'},\n",
              " {'part.': 'part'},\n",
              " {'general,': 'general'},\n",
              " {'regards,': 'regards'},\n",
              " {'state.': 'state'},\n",
              " {'sexual.': 'sexual'},\n",
              " {'views.': 'views'},\n",
              " {'rationale.': 'rationale'},\n",
              " {'entry.': 'entry'},\n",
              " {'40': '4'},\n",
              " {'past.': 'past'},\n",
              " {\"person's\": 'persons'},\n",
              " {\"someone's\": 'someones'},\n",
              " {'(who': 'who'},\n",
              " {'necessary.': 'necessary'},\n",
              " {'part,': 'part'},\n",
              " {'NPOV.': 'NOV'},\n",
              " {'()': 'in'},\n",
              " {'from.': 'from'},\n",
              " {'message,': 'message'},\n",
              " {'us,': 'us'},\n",
              " {'reasons,': 'reasons'},\n",
              " {'[]': 'in'},\n",
              " {'used,': 'used'},\n",
              " {'images.': 'images'},\n",
              " {'etc.,': 'etc.'},\n",
              " {'for,': 'for'},\n",
              " {'policy).': 'policy'},\n",
              " {'word,': 'words'},\n",
              " {'manner.': 'manner'},\n",
              " {'FACK': 'FAC'},\n",
              " {'happened.': 'happened'},\n",
              " {'week.': 'week'},\n",
              " {'appropriate,': 'appropriate'},\n",
              " {'helpful.': 'helpful'},\n",
              " {'title,': 'title'},\n",
              " {'standards.': 'standards'},\n",
              " {'story.': 'story'},\n",
              " {'behavior.': 'behavior'},\n",
              " {'Best,': 'Best'},\n",
              " {'guidelines,': 'guidelines'},\n",
              " {'bad.': 'bad'},\n",
              " {'attention.': 'attention'},\n",
              " {'page)': 'page'},\n",
              " {'neutral.': 'neutral'},\n",
              " {'(2)': '2'},\n",
              " {\"contributors'\": 'contributors'},\n",
              " {'system,': 'system'},\n",
              " {'seriously.': 'seriously'},\n",
              " {'change,': 'change'},\n",
              " {'included.': 'included'},\n",
              " {'reliable,': 'reliable'},\n",
              " {'over.': 'over'},\n",
              " {'course.': 'course'},\n",
              " {\"'s\": 'is'},\n",
              " {'(1)': '1'},\n",
              " {'down,': 'down'},\n",
              " {'truth,': 'truth'},\n",
              " {'tag,': 'tag'},\n",
              " {'address.': 'address'},\n",
              " {'\"\"personal': 'personal'},\n",
              " {'important.': 'important'},\n",
              " {'false.': 'false'},\n",
              " {'dispute.': 'dispute'},\n",
              " {'clear,': 'clear'},\n",
              " {'actions.': 'actions'},\n",
              " {'names.': 'names'},\n",
              " {'3)': '3'},\n",
              " {'cases,': 'cases'},\n",
              " {'explanation.': 'explanation'},\n",
              " {'term,': 'term'},\n",
              " {'vandalising': 'vandalizing'},\n",
              " {'months.': 'months'},\n",
              " {'past,': 'past'},\n",
              " {'friend.': 'friends'},\n",
              " {'otherwise.': 'otherwise'},\n",
              " {'says:': 'says'},\n",
              " {'best.': 'best'},\n",
              " {'care.': 'care'},\n",
              " {'(by': 'by'},\n",
              " {'policies,': 'policies'},\n",
              " {'hours.': 'hours'},\n",
              " {'paragraph.': 'paragraph'},\n",
              " {'20th': '2th'},\n",
              " {'group.': 'group'},\n",
              " {'does.': 'does'},\n",
              " {'want,': 'want'},\n",
              " {'please?': 'pleased'},\n",
              " {'following:': 'following'},\n",
              " {'exist,': 'exist'},\n",
              " {'newcomers:': 'newcomers'},\n",
              " {'far.': 'far'},\n",
              " {'claims.': 'claims'},\n",
              " {'end.': 'end'},\n",
              " {'long.': 'long'},\n",
              " {'\"\"If': 'If'},\n",
              " {'country,': 'country'},\n",
              " {'far,': 'far'},\n",
              " {'Besides,': 'Besides'},\n",
              " {'important,': 'important'},\n",
              " {'etc.)': 'etc.'},\n",
              " {'200': '2'},\n",
              " {'\"\"It': 'It'},\n",
              " {'doing.': 'doing'},\n",
              " {'wiki.': 'wiki'},\n",
              " {'either,': 'either'},\n",
              " {'re:': 're'},\n",
              " {'category.': 'category'},\n",
              " {\"editor's\": 'editors'},\n",
              " {\"'\": \"'m\"},\n",
              " {'well-known': 'wellknown'},\n",
              " {'ones.': 'ones'},\n",
              " {'can,': 'can'},\n",
              " {'he/she': 'hehe'},\n",
              " {'will.': 'will'},\n",
              " {'long,': 'long'},\n",
              " {'himself.': 'himself'},\n",
              " {'action.': 'action'},\n",
              " {'sure.': 'sure'},\n",
              " {'inclusion,': 'inclusion'},\n",
              " {'one?': 'one'},\n",
              " {'line.': 'line'},\n",
              " {'moment,': 'moment'},\n",
              " {'sentence,': 'sentence'},\n",
              " {'relevant.': 'relevant'},\n",
              " {\"website's\": 'websites'},\n",
              " {'UNBLOCK': 'UNLOCK'},\n",
              " {'bit.': 'bit'},\n",
              " {'state,': 'state'},\n",
              " {'username,': 'username'},\n",
              " {'unclear.': 'unclear'},\n",
              " {'answer.': 'answer'},\n",
              " {'19th': '9th'},\n",
              " {'two.': 'two'},\n",
              " {'below.': 'below'},\n",
              " {'means,': 'means'},\n",
              " {'ADMINS,': 'ADMIN'},\n",
              " {'really,': 'really'},\n",
              " {'further.': 'further'},\n",
              " {'anyone.': 'anyone'},\n",
              " {'support.': 'support'},\n",
              " {'different.': 'different'},\n",
              " {'idea,': 'idea'},\n",
              " {'readers.': 'readers'},\n",
              " {'game,': 'game'},\n",
              " {'Indeed,': 'Indeed'},\n",
              " {'favour': 'favor'},\n",
              " {'from,': 'from'},\n",
              " {\"page's\": 'pages'},\n",
              " {'article;': 'article'},\n",
              " {'paragraph,': 'paragraph'},\n",
              " {'knowledge,': 'knowledge'},\n",
              " {'Verifiability': 'verifiability'},\n",
              " {'mentioned.': 'mentioned'},\n",
              " {'3,': '3'},\n",
              " {'copyright.': 'copyright'},\n",
              " {'yeah,': 'yeah'},\n",
              " {'job.': 'job'},\n",
              " {']': 's'},\n",
              " {'judgement': 'judgment'},\n",
              " {'ridiculous.': 'ridiculous'},\n",
              " {';': 's'},\n",
              " {'what,': 'what'},\n",
              " {'appreciated,': 'appreciated'},\n",
              " {'joke.': 'joke'},\n",
              " {'read.': 'ready'},\n",
              " {'post.': 'post'},\n",
              " {'community,': 'community'},\n",
              " {'another.': 'another'},\n",
              " {'weezer': 'geezer'},\n",
              " {'11,': '1'},\n",
              " {'is?': 'is'},\n",
              " {'knowledge.': 'knowledge'},\n",
              " {'happen.': 'happen'},\n",
              " {'changed.': 'changed'},\n",
              " {'accurate.': 'accurate'},\n",
              " {'(from': 'from'},\n",
              " {'!!!': 'ha!'},\n",
              " {'school.': 'school'},\n",
              " {'rule,': 'rules'},\n",
              " {'law.': 'law'},\n",
              " {'sure,': 'sure'},\n",
              " {'vandalise': 'vandalism'},\n",
              " {'you:': 'you'},\n",
              " {'seriously,': 'seriously'},\n",
              " {\"'''\": \"'re\"},\n",
              " {'sourced.': 'sourced'},\n",
              " {'details.': 'details'},\n",
              " {'only.': 'only'},\n",
              " {'WP:RS': 'WPS'},\n",
              " {'cunt.': 'cunt'},\n",
              " {'(this': 'this'},\n",
              " {'tag)': 'tag'},\n",
              " {'reached.': 'reached'},\n",
              " {'opinions.': 'opinions'},\n",
              " {'there?': 'there'},\n",
              " {'school,': 'school'},\n",
              " {'Wow,': 'Wow'},\n",
              " {'username.': 'username'},\n",
              " {'ULLMANN': 'ULLMAN'},\n",
              " {'note.': 'noted'},\n",
              " {'end,': 'end'},\n",
              " {'Further,': 'Further'},\n",
              " {'irrelevant.': 'irrelevant'},\n",
              " {'Ah,': 'Ah'},\n",
              " {'arse.': 'arsed'},\n",
              " {'week,': 'week'},\n",
              " {'neutral,': 'neutral'},\n",
              " {'go,': 'go'},\n",
              " {'statement,': 'statement'},\n",
              " {'GFDL.': 'GFDL'},\n",
              " {'argument,': 'argument'},\n",
              " {'page!': 'page'},\n",
              " {'books.': 'books'},\n",
              " {'Instead,': 'Instead'},\n",
              " {'area,': 'area'},\n",
              " {'request,': 'request'},\n",
              " {'mistake,': 'mistake'},\n",
              " {'written.': 'written'},\n",
              " {'\"\"not': 'not'},\n",
              " {'organisation': 'organization'},\n",
              " {'States,': 'States'},\n",
              " {'!!': 'in'},\n",
              " {'reader.': 'readers'},\n",
              " {'his/her': 'higher'},\n",
              " {'\"\"no': 'no'},\n",
              " {'lead.': 'lead'},\n",
              " {'IP.': 'IP'},\n",
              " {'CUNT!': 'CUNT'},\n",
              " {'soon,': 'soon'},\n",
              " {'power.': 'power'},\n",
              " {'idiot.': 'idiot'},\n",
              " {'Contribs': 'Contrib'},\n",
              " {'help?': 'help'},\n",
              " {'apologise': 'apologize'},\n",
              " {'because,': 'because'},\n",
              " {'500': '5'},\n",
              " {'around,': 'around'},\n",
              " {'source?': 'source'},\n",
              " {'context,': 'context'},\n",
              " {'yours.': 'yours'},\n",
              " {'short,': 'short'},\n",
              " {'stuff,': 'stuff'},\n",
              " {'sockpuppetry': 'sockpuppet'},\n",
              " {'date,': 'date'},\n",
              " {'third-party': 'thirdparty'},\n",
              " {'period,': 'period'},\n",
              " {'verifiable.': 'verifiable'},\n",
              " {'\"\"You': 'You'},\n",
              " {'review,': 'review'},\n",
              " {'style.': 'style'},\n",
              " {'why?': 'why'},\n",
              " {'==\"': '=='},\n",
              " {'then?': 'then'},\n",
              " {'accurate,': 'accurate'},\n",
              " {'great.': 'great'},\n",
              " {'\"\"in': 'in'},\n",
              " {'theory,': 'theory'},\n",
              " {'law,': 'law'},\n",
              " {'theory.': 'theory'},\n",
              " {'wikipedians': 'wikipedia'},\n",
              " {'talk.': 'talk'},\n",
              " {'points.': 'points'},\n",
              " {'saying,': 'saying'},\n",
              " {'space.': 'space'},\n",
              " {'Personally,': 'Personally'},\n",
              " {'see:': 'see'},\n",
              " {'necessary,': 'necessary'},\n",
              " {'written,': 'written'},\n",
              " {'WTC?': 'WTC'},\n",
              " {'Sure,': 'Sure'},\n",
              " {'claim,': 'claims'},\n",
              " {'up?': 'up'},\n",
              " {'themselves,': 'themselves'},\n",
              " {'picture.': 'picture'},\n",
              " {'->': '>'},\n",
              " {'while.': 'while'},\n",
              " {'it;': 'it'},\n",
              " {'debate.': 'debate'},\n",
              " {'alone,': 'alone'},\n",
              " {'SHANNON!': 'SHANNON'},\n",
              " {'MONGO?': 'MONO'},\n",
              " {'sourced,': 'sourced'},\n",
              " {'etc,': 'etc'},\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f1c0ngmzU8q0"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JrvTqpVJDsD",
        "colab_type": "text"
      },
      "source": [
        "Read the glove word vectors (space delimited strings) into a dictionary from word->vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EZA6pm719a7Y",
        "colab": {}
      },
      "source": [
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6SzGrxgJDsF",
        "colab_type": "text"
      },
      "source": [
        "Use these vectors to create our embedding matrix, with random initialization for words that aren't in GloVe. We'll use the same mean and stdev of embeddings the GloVe has when generating the random init."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OVKR-lVt9gTZ",
        "outputId": "601e6362-1b60-421f-ca90-4838cc1e43b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "emb_mean,emb_std"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.020940498, 0.6441043)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zwF55Rwv8y5M",
        "outputId": "4829d782-5020-4129-fd48-57daa199ce0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "nb_words"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZSjYF_D59o-r",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uLINrfvHJOsK"
      },
      "source": [
        "Simple bidirectional LSTM with two fully connected layers. We add some dropout to the LSTM since even 2 epochs is enough to overfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IRZk69ap9xcs",
        "colab": {}
      },
      "source": [
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(50, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(6, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FzCFdbkw79qi",
        "colab": {}
      },
      "source": [
        "??LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urBUs7QU9y7p",
        "outputId": "39f0cf11-0aca-443a-9a5e-f13ec079b50a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "model.fit(X_t, y, batch_size=32, epochs=2, validation_split=0.1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/2\n",
            "143613/143613 [==============================] - 1745s 12ms/step - loss: 0.0622 - acc: 0.9787 - val_loss: 0.0499 - val_acc: 0.9821\n",
            "Epoch 2/2\n",
            "143613/143613 [==============================] - 1761s 12ms/step - loss: 0.0455 - acc: 0.9829 - val_loss: 0.0467 - val_acc: 0.9830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f694423e668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rXXOeC6Awk_h",
        "colab": {}
      },
      "source": [
        "model.save('LSTM.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AskFXXWAkVep",
        "colab": {}
      },
      "source": [
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-KwzyjPqBD33",
        "outputId": "b5a795a5-acde-4ba0-e538-e87132f9f8e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_preds_np = model.predict([X_te], batch_size=1024, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 19s 123us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rOe_5tBg9RD2",
        "colab": {}
      },
      "source": [
        "sample_submission = pd.read_csv(f'{path}sample_submission.csv')\n",
        "sample_submission[list_classes] = y_preds_np\n",
        "sample_submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zfP3DRwBvqPK",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "conMat = confusion_matrix(y_true=y.argmax(axis=1), y_pred=y_preds_np.argmax(axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NOgaF9bovq7z",
        "colab": {}
      },
      "source": [
        "df_cm = pd.DataFrame(conMat, index = [i for i in target_columns], columns = [i for i in target_columns])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pRvKdOdSAu_t",
        "outputId": "c1eb4d79-c263-4b45-f8f2-e9596f78df45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "custom_test = tokenizer.texts_to_sequences(['Nonsense? kiss off, geek. What I said is true.. I\\'ll have your account terminated.'])\n",
        "custom_test_ter = pad_sequences(custom_test, maxlen=maxlen)\n",
        "model.predict(custom_test_ter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5177543 , 0.00234741, 0.05660301, 0.01019084, 0.11131756,\n",
              "        0.00309392]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NjgF4lvkJxLV",
        "outputId": "db213dca-83bb-4908-a9ca-98367bfd3710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "custom_test = tokenizer.texts_to_sequences(['I love PXL.'])\n",
        "custom_test_ter = pad_sequences(custom_test, maxlen=maxlen)\n",
        "model.predict(custom_test_ter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.85095382e-03, 6.64591789e-06, 6.83635473e-04, 3.62992287e-05,\n",
              "        5.73695637e-04, 1.07490516e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YN23XwKnKN0G",
        "outputId": "aec0c2d4-ce57-4a95-9139-6176c2c1d7c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "custom_test = tokenizer.texts_to_sequences(['I love my mom.'])\n",
        "custom_test_ter = pad_sequences(custom_test, maxlen=maxlen)\n",
        "model.predict(custom_test_ter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12829536, 0.00045675, 0.0118587 , 0.00201872, 0.02777336,\n",
              "        0.00158019]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}